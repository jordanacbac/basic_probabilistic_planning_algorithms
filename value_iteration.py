from argparse import ArgumentParser
import numpy as np
import pandas as pd
import re
import random
import time

def create_states(content_list):
	# States are represented by a list
	states = []

	for pos in range(len(content_list)):
		# Identifying the line that precedes the states
		if(content_list[pos] == 'states'):
			# Appending all the states
			states.append(content_list[pos+1].split(', '))
	
	return (states[0])

def create_actions(content_list):
	# Actions are represented by a dictionary
	actions = {}
	# Defining regex to catch the action's name
	pattern = '^action .*'
	
	for pos in range(len(content_list)):
		# Identifying the line containing the action's name
		if(re.match(pattern, content_list[pos])):
			# Generating a key with the action's name and receiving an empty list as value 
			actions[str(content_list[pos]).replace('action ', '')] = []
			new_pos = pos + 1
			# Loop responsible for all the action details storage
			while(content_list[new_pos] != 'endaction'):
				actions[str(content_list[pos]).replace('action ', '')].append(content_list[new_pos].split(' '))
				new_pos += 1

	# If necessary, method to clean the actions (remove the discard element)
	actions = clean_actions(actions)
	return (actions)

def create_costs(content_list):
	# Costs are represented by a list
	costs = []

	for pos in range(len(content_list)):
		# Identifying the line that precedes the costs
		if(content_list[pos] == 'cost'):
			pos += 1
			while(content_list[pos] != 'endcost'):
				costs.append(content_list[pos].split(' '))
				pos += 1
			break

	return (costs)

def create_initial_and_goal_states(content_list):
	
	for pos in range(len(content_list)):
		if(content_list[pos] == 'initialstate'):
			init = content_list[pos+1]
		if(content_list[pos] == 'goalstate'):
			goal = content_list[pos+1]
	
	return (init, goal)

def clean_actions(actions):
	for action in actions:
		for item in actions.get(action):
			item.pop(3)
	
	return (actions)

def create_states_view(costs):
	states = []
	states_view = {}
	for element in costs:
		states.append(element[0])
	states = set(states)
	for state in states:
		states_view[state] = []
	
	for element in costs:
		for state in states:
			if (element[0] == state):
				states_view[state].append(element[1:])

	states_view_complete = states_view.copy()
	for state in states_view:
		for pos in range(len(states_view.get(state))):
			action = states_view.get(state)[pos][0]
			for act in actions:
				if (act == action):
					for el in actions.get(act):
						if (el[0] == state):
							states_view_complete.get(state)[pos].extend(el[1:])
	
	return (states_view_complete)

def create_df_states(states):
	# Creating dataframe from states
	df = pd.DataFrame(states)
	# Giving the only column a name (states)
	df.columns = ['states']

	# Setting states as dataframe index
	df.set_index('states', inplace=True)

	# Transposing the dataframe
	df_t = df.T

	return(df_t)

def iterative_policy_evaluation(df, states_view):
	df = choose_proper_policy(df, states_view)
	return

def bellman_backup(state, states_view, df, n):#devolve Q do estado na iteracao n
	
	# Next steps: Calculate Q*(state, action) and V*(state)
	#df vai ser a tabela com tds valores de cada iteracao n
	#Calc Q*
	# get actions
	actions = states_view.get(state)
	Q = []
	for action in actions:
		# check if it has more than 1 state for each move
		if len(action) == 4:
			Q.append( float(action[1]) + float(df.loc[n-1, action[2]] ) )
		else:
			# if it has more than 1 result, compute the probability
			Q_value = 0
			for num_states in range (2, len(action), 2):
				Q_value += ( float(action[num_states+1]) * float(df.loc[n-1, action[num_states]]) )
			Q.append(float(action[1]) + Q_value ) 
	return( min(Q) )	

def value_iteration(df, states_view):
	# Pseudo random numbers generated by the following seed:
	random.seed(324)
	
	t = time.time()

	# Generating the pseudo random numbers for each state (numbers interval from 0 to 10):
	for i in df.columns:
		df.loc[0, i] = random.randint(0,10)
	print(df)

	# df.loc[0, 'robot-at-x1y1'] = 'aaaa' # posicao do valor
	# print(df)
	df_residual = df.copy()
	for i in df_residual.columns:
		df_residual.loc[0, i] = 999
	df_residual.loc[0, "robot-at-x20y20"] = 0

	epsilon = 0.5
	n = 0
	# TODO: while max residual < epsilon
	while(True):
		n += 1

		for state in df.columns:

			#nao sei como tratar
			#if state == "robot-at-x20y20":
			#	continue

			# calculate bellman backup
			Vn = bellman_backup(state, states_view, df, n)

			#compute residual
			df_residual.loc[n-1, state] = abs(Vn - df.loc[n-1, state]) 

			# update Value
			df.loc[n, state] = Vn

		# check epsilon
		df_check = df_residual.transpose()
		max_residual = float(df_check.max())
		print(df_residual)
		if max_residual < epsilon:
			break


	t = time.time() - t
	print("Value iteration: " + str(n) + " iterations, runtime: " + str(t) )

	return

#retorna df com politica propria
def choose_proper_policy(df, states_view):#df das iteracoes, states_view tds acoes de cada estado
	pos_state = 0
	for state in df.columns:
		action_chosen = ''
		out = 0 #1 eh para sair
		while(out == 0):
			action_random = randrange(4)
			actions = states_view.get(state)
			i = 0
			for act in actions:
				if (i = action_random):
					if((act[2] != state) or (float(act[3]) != 1)):#se prox estado nao eh igual o atual ou prob nao eh 1, pode
						action_chosen = act[0]
						out = 1
						break
				else:
					i+=1
		df.loc[0, state] = action_chosen #vai armazenar 'move-north',...
		pos_state+=1
	return df

if __name__ == '__main__':

	# Creating script argument to indicate the problem file that must be read
	#parser = ArgumentParser()
	#parser.add_argument("-f", "--file", dest="filename", help="file to be read", metavar="FILE")
	#args = parser.parse_args()
	
	# Generating a list for the file content and reading it
	content_list = []
	with open("C:/Users/Laura Takako/Documents/tpia - ep2/planejamentoEmIA_ep2/TestesGrid/FixedGoalInitialState/navigation_1.net") as file:
		content = file.readlines()
	
	# Replacing "\t", spliting the file on line breaks and filling in the list with the file's content
	for element in content:
		content_list.append(element.replace('\t', '').split('\n')[0])

	# Calling the method responsible to create the list of states
	states = create_states(content_list)
	#print(states)
	
	# Calling the method responsible to create the dict of actions
	actions = create_actions(content_list)
	#print(actions)

	# Calling the method responsible to create the list of costs
	costs = create_costs(content_list)
	#print(costs)
	
	# Calling the method responsible to read the initial and the goal state
	initial, goal = create_initial_and_goal_states(content_list)
	#print(initial, goal)

	# Generating states view to run value iteration algorithm
	# states_view is a dictionary in which states are keys and their values are lists containing applicable actions and their costs, followed by the resulting states and their probabilities.
	states_view = create_states_view(costs)
	# print(states_view)
	
	# Calling the method responsible to create a dataframe from the list of states
	df = create_df_states(states)

	# Next steps:
	value_iteration(df, states_view)

	## Proximo passo: checar a melhor estrutura de dados para armazenar os estados e gerar a matriz
	## O que pretendo fazer: criar um dataframe e converter para numpy array depois.
	## https://stackoverflow.com/questions/26173486/create-matrix-with-column-names-and-row-names-in-python/28380345